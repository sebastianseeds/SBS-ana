{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "above-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collectible-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cut_string_from_json(filename, json_file_path):\n",
    "    \"\"\"\n",
    "    Extracts a cut string from a JSON file based on elements derived from a filename.\n",
    "\n",
    "    :param filename: The name of the file, used to derive the key for accessing the JSON data.\n",
    "    :param json_file_path: The path to the JSON file containing cut strings.\n",
    "    :return: The cut string corresponding to the given filename.\n",
    "    \"\"\"\n",
    "    # Load the JSON file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Extract 'section' and 'section2' from the filename\n",
    "    section = filename.split('_')[2]\n",
    "    section2_raw = filename.split('_')[3]\n",
    "    section2 = section2_raw.rstrip('p')  # Removes the trailing 'p'\n",
    "\n",
    "    # Construct the subkey for accessing the JSON data\n",
    "    subkey = f\"{section}_{section2}\"  # Adjust this format as needed\n",
    "\n",
    "    # Access the data using the key and subkey\n",
    "    cut_string = data[\"post_cuts_p2\"].get(subkey, \"Default cut string if not found\")\n",
    "\n",
    "    mod_cut_string = cut_string.replace(\"&&\", \" and \")\n",
    "    \n",
    "    return mod_cut_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wicked-outreach",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_specific_cuts(cut_string, cuts_to_remove):\n",
    "    \"\"\"\n",
    "    Removes specific conditions from the cut string, anticipating conversion to ' and '.\n",
    "    \n",
    "    :param cut_string: The original cut string containing all conditions.\n",
    "    :param cuts_to_remove: A list of conditions (as strings) to remove from the cut string.\n",
    "    :return: The modified cut string with specified conditions removed.\n",
    "    \"\"\"\n",
    "    # Convert \"&&\" to \" and \" for consistency in removal and further processing\n",
    "    cut_string = cut_string.replace(\"&&\", \" and \")\n",
    "    \n",
    "    for cut in cuts_to_remove:\n",
    "        # Remove the specific cut with careful handling of leading/trailing spaces\n",
    "        pattern = rf'\\band\\s+{cut}\\b|\\b{cut}\\s+and\\b|\\b{cut}\\b'\n",
    "        cut_string = re.sub(pattern, '', cut_string, flags=re.IGNORECASE)\n",
    "\n",
    "    # Clean up: Remove any leading or trailing 'and ', and replace multiple occurrences of 'and' with a single 'and'\n",
    "    cut_string = re.sub(r'^and\\s+', '', cut_string).strip()  # Remove 'and ' at the start\n",
    "    cut_string = re.sub(r'\\s+and$', '', cut_string).strip()  # Remove 'and ' at the end\n",
    "    cut_string = re.sub(r'\\band\\s+and\\b', ' and ', cut_string)  # Replace 'and and' with 'and'\n",
    "    cut_string = re.sub(r'\\s+and\\s+', ' and ', cut_string)  # Ensure single space around 'and'\n",
    "\n",
    "    return cut_string\n",
    "\n",
    "# Example usage:\n",
    "#cut_string = \"bb_tr_n==1 && hcale>0.04 && abs(bb_tr_vz)<0.075 && abs(dy+0.03)<0.80 && bb_ps_e>0.2 && abs(W2-0.92)<0.72 && bb_gem_track_nhits>3 && abs(bb_etot_over_p-0.993)<0.240 && hcalnblk>0 && abs(coin-0.54)<7.0 && hcalon==1 && mag==100\"\n",
    "#cuts_to_remove = [\"mag==100\", \"hcalon==1\"]\n",
    "#modified_cut_string = remove_specific_cuts(cut_string, cuts_to_remove)\n",
    "#print(modified_cut_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reverse-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_specific_cuts(cut_string, cuts_to_remove):\n",
    "    \"\"\"\n",
    "    Removes specific conditions from the cut string, anticipating conversion to ' and '.\n",
    "    \n",
    "    :param cut_string: The original cut string containing all conditions.\n",
    "    :param cuts_to_remove: A list of conditions (as strings) to remove from the cut string.\n",
    "    :return: The modified cut string with specified conditions removed.\n",
    "    \"\"\"\n",
    "    # Convert \"&&\" to \" and \" for consistency in removal and further processing\n",
    "    cut_string = cut_string.replace(\"&&\", \" and \")\n",
    "    \n",
    "    for cut in cuts_to_remove:\n",
    "        # Escape special characters in the cut to be removed\n",
    "        cut_escaped = re.escape(cut)\n",
    "        \n",
    "        # Remove the specific cut with careful handling of leading/trailing spaces\n",
    "        pattern = rf'\\band\\s+{cut_escaped}\\b|\\b{cut_escaped}\\s+and\\b|\\b{cut_escaped}\\b'\n",
    "        cut_string = re.sub(pattern, '', cut_string, flags=re.IGNORECASE)\n",
    "\n",
    "    # Clean up: Remove any leading or trailing 'and ', and replace multiple occurrences of 'and' with a single 'and'\n",
    "    cut_string = re.sub(r'^and\\s+', '', cut_string).strip()  # Remove 'and ' at the start\n",
    "    cut_string = re.sub(r'\\s+and$', '', cut_string).strip()  # Remove 'and ' at the end\n",
    "    cut_string = re.sub(r'\\band\\s+and\\b', ' and ', cut_string)  # Replace 'and and' with 'and'\n",
    "    cut_string = re.sub(r'\\s+and\\s+', ' and ', cut_string)  # Ensure single space around 'and'\n",
    "\n",
    "    return cut_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "amazing-portfolio",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_specific_cuts(cut_string, cuts_to_remove):\n",
    "    \"\"\"\n",
    "    Removes specific conditions from the cut string.\n",
    "    \n",
    "    :param cut_string: The original cut string containing all conditions.\n",
    "    :param cuts_to_remove: A list of conditions (as strings) to remove from the cut string.\n",
    "    :return: The modified cut string with specified conditions removed.\n",
    "    \"\"\"\n",
    "    for cut in cuts_to_remove:\n",
    "        # Ensure to handle both the cut and its possible variations in spacing around '&&'\n",
    "        cut_string = cut_string.replace(f\"&&{cut}\", \"\").replace(f\"{cut}&&\", \"\").replace(cut, \"\")\n",
    "    return cut_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "reserved-terrorism",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_histogram_from_file(filename, cut_string):\n",
    "    # Extract the section from the filename for the title\n",
    "    section = filename.split('_')[2]\n",
    "    section2 = filename.split('_')[3]\n",
    "    \n",
    "    # Load the tree\n",
    "    file = uproot.open(f\"/lustre19/expphy/volatile/halla/sbs/seeds/parse/{filename}\")\n",
    "    tree = file[\"P\"]\n",
    "    \n",
    "    # Load the branches as arrays\n",
    "    dx_array = tree[\"dx\"].array(library=\"np\")\n",
    "    nucleon_array = tree[\"nucleon\"].array(library=\"np\")\n",
    "    weights_array = tree[\"mc_weight_norm\"].array(library=\"np\")\n",
    "    \n",
    "    # Apply the cuts based on the nucleon condition\n",
    "    dx_p_array = dx_array[nucleon_array == 0]  # nucleon==0\n",
    "    dx_n_array = dx_array[nucleon_array == 1]  # nucleon==1\n",
    "    weights_p_array = weights_array[nucleon_array == 0]\n",
    "    weights_n_array = weights_array[nucleon_array == 1]\n",
    "    \n",
    "    # Define custom binning within the range of -2 to 1\n",
    "    bins = np.linspace(-2, 1, 200)\n",
    "    bin_width = (bins[1] - bins[0]) / 2  # Calculate half the bin width\n",
    "        \n",
    "    # Calculate the integrals (weighted sums) and the number of events\n",
    "    integral_p = np.sum(weights_p_array)\n",
    "    integral_n = np.sum(weights_n_array)\n",
    "    N_p = len(dx_p_array)\n",
    "    N_n = len(dx_n_array)\n",
    "\n",
    "    # Calculate the ratio of N_n to N_p\n",
    "    ratio_n_p = integral_n / integral_p\n",
    "    \n",
    "    # Double the overall size of the plot\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # Calculate the histograms using numpy.histogram for the outlined sum\n",
    "    counts, edges = np.histogram(dx_array, bins=bins, weights=weights_array)\n",
    "    \n",
    "    # Shift edges to the right by half a bin width\n",
    "    shifted_edges = edges[:-1] + bin_width\n",
    "\n",
    "    # Create histograms with weights\n",
    "    plt.hist(dx_p_array, bins=bins, weights=weights_p_array, label=f'dx_p (proton) weighted, N={integral_p:.2f}', alpha=0.75)\n",
    "    plt.hist(dx_n_array, bins=bins, weights=weights_n_array, label=f'dx_n (neutron) weighted, N={integral_n:.2f}', alpha=0.75)\n",
    "    \n",
    "    # Plot using plt.step for a histogram-like line plot\n",
    "    plt.step(shifted_edges, counts, where='mid', color='black', linewidth=2, label=f'dx (sum) weighted')\n",
    "\n",
    "    # Add a dummy plot for the ratio of N_n to N_p in the legend\n",
    "    plt.plot([], [], ' ', label=f'Ratio of N_n to N_p: {ratio_n_p:.2f}')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.xlabel('dx', fontsize='xx-large')\n",
    "    plt.ylabel('Counts', fontsize='xx-large')\n",
    "    plt.title(f'Histograms of dx, dx_p, and dx_n with Weights and Cuts for {section} {section2}', fontsize='xx-large')\n",
    "    plt.xlim(-2, 1)  # Set the x-axis limits\n",
    "    plt.legend(fontsize='xx-large')\n",
    "    plt.grid(True)  # Add grid lines\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "voluntary-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_from_file(filename, modified_cut_string):\n",
    "    # Extract the section from the filename for the title\n",
    "    section = filename.split('_')[2]\n",
    "    section2_raw = filename.split('_')[3].rstrip('p')  # Removes the trailing 'p'\n",
    "    \n",
    "    # Load the tree\n",
    "    file = uproot.open(f\"/lustre19/expphy/volatile/halla/sbs/seeds/parse/{filename}\")\n",
    "    tree = file[\"P\"]\n",
    "        \n",
    "    # Load the branches as arrays and create a DataFrame\n",
    "    branches = tree.arrays([\"dx\", \"W2\", \"nucleon\", \"mc_weight_norm\", \"bb_ps_e\", \"hcale\", \"dy\", \"bb_etot_over_p\", \"hcalnblk\", \"bb_gem_track_nhits\", \"fiducial_sig_x\", \"fiducial_sig_y\", \"hcalon\", \"coin\", \"bb_tr_vz\"], library=\"pd\")\n",
    "    \n",
    "    print(\"Columns in DataFrame:\", branches.columns)\n",
    "    \n",
    "    # Define custom binning within the range of -2 to 1\n",
    "    bins = np.linspace(-2, 1, 200)\n",
    "    bin_width = (bins[1] - bins[0]) / 2  # Calculate half the bin width\n",
    "    \n",
    "    # Apply cuts using query method on DataFrame\n",
    "    branches = branches.query(modified_cut_string)\n",
    "\n",
    "    # After applying cuts, separate proton and neutron data based on the 'nucleon' condition\n",
    "    dx_p_array = branches[branches['nucleon'] == 0]['dx']\n",
    "    dx_n_array = branches[branches['nucleon'] == 1]['dx']\n",
    "    weights_p_array = branches[branches['nucleon'] == 0]['mc_weight_norm']\n",
    "    weights_n_array = branches[branches['nucleon'] == 1]['mc_weight_norm']\n",
    "\n",
    "    # Calculate the integrals (weighted sums) and the number of events after cuts\n",
    "    integral_p = weights_p_array.sum()\n",
    "    integral_n = weights_n_array.sum()\n",
    "    N_p = dx_p_array.size\n",
    "    N_n = dx_n_array.size\n",
    "\n",
    "    # Calculate the ratio of N_n to N_p\n",
    "    ratio_n_p = integral_n / integral_p if integral_p else np.nan\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(20, 12))\n",
    "\n",
    "    # Create histograms with weights after cuts\n",
    "    plt.hist(dx_p_array, bins=bins, weights=weights_p_array, label=f'dx_p (proton) weighted, N={integral_p:.2f}', alpha=0.75)\n",
    "    plt.hist(dx_n_array, bins=bins, weights=weights_n_array, label=f'dx_n (neutron) weighted, N={integral_n:.2f}', alpha=0.75)\n",
    "    \n",
    "    # Add a dummy plot for the ratio of N_n to N_p in the legend\n",
    "    plt.plot([], [], ' ', label=f'Ratio of N_n to N_p: {ratio_n_p:.2f}')\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel('dx', fontsize='xx-large')\n",
    "    plt.ylabel('Counts', fontsize='xx-large')\n",
    "    plt.title(f'Histograms of dx, dx_p, and dx_n with Weights and Cuts for {section} {section2_raw}', fontsize='xx-large')\n",
    "    plt.xlim(-2, 1)\n",
    "    plt.legend(fontsize='xx-large')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collect-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = '/w/halla-scshelf2102/sbs/seeds/ana/config/syst.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "olympic-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the cuts to remove\n",
    "cuts_to_remove = [\"mag==70\", \"mag==100\", \"mag==30\", \"mag==85\", \"tar==1\", \"bb_tr_n==1\", \"abs(coin-0.54)<7.0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exact-movement",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# List of files\n",
    "files = [\n",
    "    \"parse_mc_sbs11_100p_barebones.root\",\n",
    "    \"parse_mc_sbs14_70p_barebones.root\",\n",
    "    \"parse_mc_sbs4_30p_barebones_alt.root\",\n",
    "    \"parse_mc_sbs4_30p_barebones.root\",\n",
    "    \"parse_mc_sbs4_50p_barebones.root\",\n",
    "    \"parse_mc_sbs7_85p_barebones.root\",\n",
    "    \"parse_mc_sbs9_70p_barebones_alt.root\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "respiratory-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of files\n",
    "files = [\n",
    "    \"parse_mc_sbs4_30p_barebones_alt.root\",\n",
    "    \"parse_mc_sbs4_30p_barebones.root\",\n",
    "    \"parse_mc_sbs4_50p_barebones.root\",\n",
    "    \"parse_mc_sbs9_70p_barebones_alt.root\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "destroyed-borough",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_cut_string_from_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3199210bb24e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loop over the files and plot histograms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcut_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cut_string_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodified_cut_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_specific_cuts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuts_to_remove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_cut_string_from_json' is not defined"
     ]
    }
   ],
   "source": [
    "# Loop over the files and plot histograms\n",
    "for filename in files:\n",
    "    cut_string = get_cut_string_from_json(filename, json_file_path)\n",
    "    print(cut_string)\n",
    "    modified_cut_string = remove_specific_cuts(cut_string, cuts_to_remove)\n",
    "    print(modified_cut_string)\n",
    "    plot_histogram_from_file(filename, modified_cut_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-james",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
